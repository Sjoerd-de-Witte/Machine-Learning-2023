{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sjoerd-de-Witte/Machine-Learning-2023/blob/main/4_3_Balancing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown -O /tmp/ml.py 174lBNvDBJSVWs3OpNL3a68cnhWIcWYuY\n",
        "%run /tmp/ml.py"
      ],
      "metadata": {
        "id": "Ysk5_dggcLUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6eddd80-2146-4d2c-b865-54fddcbc919e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=174lBNvDBJSVWs3OpNL3a68cnhWIcWYuY\n",
            "To: /tmp/ml.py\n",
            "\r  0% 0.00/1.31k [00:00<?, ?B/s]\r100% 1.31k/1.31k [00:00<00:00, 4.76MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybjfaxScK1e"
      },
      "source": [
        "# Balancing\n",
        "\n",
        "Most datasets are inbalanced, and this is something to be very much aware of when you solve problems. The accuracy paradox tells us that if 90% of the data has the same label, than a random classifier will already reward us with 90% accuracy. One of the things to check is the skew of the dataset, to see if the accuracy paradox applies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DXIdB7UncK1m"
      },
      "outputs": [],
      "source": [
        "from pipetorch import Kaggle\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I30OZApccK1p"
      },
      "source": [
        "# Data\n",
        "\n",
        "Suppose that we really want to buy a good bottle of wine, but a bottle that just received a '6' does not really qualify for our intents and purposes, therefore we would like a bottle that received at least a 7. It turns out, that only 13.5% of the wines in our dataset meet this requirement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UmL4txlhcK1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ed20a6-2a47-4fa1-e2ff-f2adc43f0eef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset uciml/red-wine-quality-cortez-et-al-2009 from kaggle to /root/.pipetorchuser/red-wine-quality-cortez-et-al-2009\n"
          ]
        }
      ],
      "source": [
        "filepath = Kaggle('uciml/red-wine-quality-cortez-et-al-2009').file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BqxKsAfmcK1r",
        "outputId": "4fe515ce-70fd-490f-a3a4-b9c9632a51a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1357098186366479"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv(filepath)\n",
        "df.quality = df.quality > 6\n",
        "# how many bottles of wine are rated as good?\n",
        "sum(df.quality)/len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uQ3WH0dhcK1u"
      },
      "outputs": [],
      "source": [
        "# Split the dataset in a train and validation set.\n",
        "# use 20% of the dataset for validation.\n",
        "# in this case, keep X and y together to make it easier to balance in part 2\n",
        "train, valid = train_test_split(df, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OKzHhSI_cK1v",
        "outputId": "8137715f-929a-489e-a1f4-91a3b204a83f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.46376811594202894"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# create train_X, valid_X, etc. quality is the target variable,\n",
        "# report the F1 score\n",
        "train_X = train.drop(columns='quality').to_numpy()\n",
        "train_y = train.quality.to_numpy()\n",
        "valid_X = valid.drop(columns='quality').to_numpy()\n",
        "valid_y = valid.quality.to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_X_scaled = scaler.fit_transform(train_X)\n",
        "valid_X_scaled = scaler.transform(valid_X)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(train_X, train_y)\n",
        "\n",
        "pred_y = model.predict(valid_X)\n",
        "\n",
        "f1_score(valid_y, pred_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-YY0O0EcK1w"
      },
      "source": [
        "Then when we check the F1 Score, we probably see that the model is underperforming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gofg03S7cK1x"
      },
      "source": [
        "# balance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A3QwT0bScK1y",
        "outputId": "eb904a83-c011-432d-870f-8b09917218aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quality\n",
              "False    1109\n",
              "True      170\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train.groupby(by='quality').quality.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G1flzw0McK10",
        "outputId": "0dba60cd-d5bd-4abb-8278-ef1ffd551705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5985401459854015"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Try to balance the data using 'resample', then fit the model again and report the F1 Score\n",
        "train_resampled = pd.concat([train[train.quality==0],\n",
        "                            resample(train[train.quality==1], n_samples=1100)])\n",
        "\n",
        "train_X_resampled = train_resampled.drop(columns='quality').to_numpy()\n",
        "train_y_resampled = train_resampled.quality.to_numpy()\n",
        "\n",
        "valid_X = valid.drop(columns='quality').to_numpy()\n",
        "valid_y = valid.quality.to_numpy()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "train_X_scaled = scaler.fit_transform(train_X)\n",
        "valid_X_scaled = scaler.transform(valid_X)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(train_X_resampled, train_y_resampled)\n",
        "\n",
        "pred_y = model.predict(valid_X)\n",
        "\n",
        "f1_score(valid_y, pred_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7Uo_QE3cK12"
      },
      "outputs": [],
      "source": [
        "halt_notebook()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}